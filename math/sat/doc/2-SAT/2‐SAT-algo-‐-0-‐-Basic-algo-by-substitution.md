The basic [2-SAT](2%E2%80%90SAT) algorithm applies [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming) by eliminating variables in a simple form: substituting $True$ and $False$ to variables.

# Variable elimiation by substitution

Maybe an easy way to understand variable elimination is by looking into a sample. Lets say we have the following 2-SAT problem:

$$
(x_1 \lor \neg x_2) \land (x2 \lor \neg x_3) \land (x_3 \lor \neg x1)
$$

First lets eliminate $x1$. Since it can be either $True$ or $False$, this will generate two new problems:

$$
(x_1 \lor \neg x_2) \land (x2 \lor \neg x_3) \land (x_3 \lor \neg x1) \iff
$$
$$
x_1 = True: (x2 \lor \neg x_3) \land (x_3)
$$
$$
x_1 = False: (\neg x_2) \land (x2 \lor \neg x_3)
$$

For instance in the $x_1 = True$ case the first clause of the original problem, $(x_1 \lor \neg x_2)$ is already satisfied by $x_1$ and the last one, $(x_3 \lor \neg x1)$ can only be satisfied by $x_3$, since $\neg x_1$ is $False$ in this case. Similar applies to the other case, when we eliminate $x_1$ by setting $x_1 = False$.

Now lets eliminate $x_2$. Then we can get at most 4 new problems, in real it will be less. For instance lets see the case when $x_1$ was eliminated by setting $x_1 = True$ and now lets eliminate $x_2$. We get:

$$
(x_1 \lor \neg x_2) \land (x2 \lor \neg x_3) \land (x_3 \lor \neg x1), x_1 = True \iff (x_2 \lor \neg x_3) \land (x_3) \iff
$$
$$
x_2 = True: (x_3)
$$
$$
x_2 = False: False \land True
$$

The second clause, when $x_2 = False$ is however clearly unsatisfiable, hence eliminating $x_1$ and $x_2$ in this direction leads to only one problem:

$$
(x_3)
$$

Which is then trivially satisfied by $x3 = True$. So we found a solution:

$$
x_1 = True, x_2 = True, x_3 = True
$$

In similar way we can find the other solution in the other direction, when $x_1$ is set $x_1 = False$:

$$
x_1 = False, x_2 = False, x_3 = False
$$

# Dynamic programming

The idea of the basic algo is to apply dynamic programming by variable substitution. We reduce the number of variables by substitution, well... in the cost of generating new 2-SAT problems. The dynamic programming idea is to connect new problems to the earlier ones (i.e. a new problem is connected to the previous problem from which it emerged during the substitution). Its a form of recursion. This case it results in a compute graph arranged into a two dimensional matrix, where

- 1st dimension is the number of variables between 1 and the total number of variables in the original problem (or if one tolerates somewhat abstract cases then we can go down to 0 and accept the degenerate case of 0 variable 2-SAT problems where each clause is simply either $True$ or $False$)
- 2nd dimension is the 2-SAT problems including the original problem and the ones generated by dynamic programming
- Each node (or cell in the matrix) hence have a number, representing the $number$ $of$ $variables$ and a $2-SAT$ $problem$. These nodes are determined dynamically by recursively eliminating variables in different directions back from the original problem.
- Nodes are connected (with directed edges) iff one node is generated from the other by variable elimination.
- The graph represents all solutions (if any) through connected edges (aka [path](https://en.wikipedia.org/wiki/Path_(graph_theory))). One just have to read the labels of an N-length path, containing each variable, this then gives a solution to the original problem

Note that this will be a sparse matrix, since the dimensions are not independent, the 2nd dimension already determines the 1st. We still think of the compute graph this way because of the following:

From the point of view of proof, the compute graph can be seen an inductive proof: 

- dynamic programming as an induction reduces a problem to some other problems with lower number of variables until
- it is reduced to trivial case (trivially satisfied or trivially unsatisfiable)

# Simplification

Besides dynamic programming we can also use simplification in order to 

- eliminate trivial problems (such as when there are trival $True \land False$ contradiction in a subproblem - see example above) and
- bring problems to canonical form (such as when there are 1 variable clauses in the problem, it can be simplified, maybe recursively, to a problem where each clause has 2 variables or to a problem where each clause has 1 variables (1-SAT which is trivially satisfied or unsatisfiable) - again see example above)

# Complexity

The basic algorithm works since it is finite. However it is exponential (cannot guarantee better), since the number of problems may grow exponentially by each substitution step. There can be early ends when a substitution leads to a trivial problem (such as a contradiction - see Simplifications above) but this is just a heuristic, the algorithm itself cannot guarantee that the number of problems will not grow exponentially.

# Wrapup

We 

- failed to find a polynomial algrithm 

yet:

- we found a finite algorithm and
- gained some insights to the problem: 
  - a simplification technique: if a variable always appears in the same form
  - contradictions
  - why the basic algo fails: if some of the variables appear in different forms
# Reference

- https://en.wikipedia.org/wiki/Dynamic_programming